import streamlit as st
import pandas as pd
import os
from processor import process_document_to_dataframe

st.set_page_config(page_title="æ ‡å‡†æ•°å­—åŒ–ç³»ç»Ÿ", layout="wide")

# --- ç¯å¢ƒæ£€æŸ¥åŒº ---
with st.sidebar:
    st.header("âš™ï¸ ç¯å¢ƒè¯Šæ–­")
    tess_exists = os.path.exists(r'C:\Program Files\Tesseract-OCR\tesseract.exe')
    if tess_exists:
        st.success("Tesseract å¼•æ“å·²å°±ç»ª")
    else:
        st.error("æœªæ‰¾åˆ° Tesseractï¼è¯·æ£€æŸ¥è·¯å¾„")

DB_FILE = "processed_database.csv"

# --- æ ¸å¿ƒåŒæ­¥é€»è¾‘ (å•çº¿ç¨‹æœ€ç¨³ç‰ˆ) ---
def sync_data():
    if not os.path.exists("data"):
        os.makedirs("data")
        return pd.DataFrame()

    db_df = pd.read_csv(DB_FILE) if os.path.exists(DB_FILE) else pd.DataFrame()
    processed = set(db_df['æ¥æºæ–‡ä»¶'].unique()) if not db_df.empty else set()
    
    current_files = [f for f in os.listdir("data") if f.lower().endswith(('.pdf', '.docx'))]
    new_files = [f for f in current_files if f not in processed]

    if new_files:
        progress_text = st.empty()
        pbar = st.progress(0)
        new_data = []
        
        for i, f in enumerate(new_files):
            progress_text.text(f"æ­£åœ¨å¤„ç† ({i+1}/{len(new_files)}): {f}")
            df_item = process_document_to_dataframe(os.path.join("data", f))
            if not df_item.empty:
                new_data.append(df_item)
            pbar.progress((i + 1) / len(new_files))
        
        if new_data:
            db_df = pd.concat([db_df] + new_data, ignore_index=True)
            # æ£€æŸ¥ CSV æ˜¯å¦è¢«å ç”¨
            try:
                db_df.to_csv(DB_FILE, index=False)
                st.success("æ•°æ®åº“æ›´æ–°æˆåŠŸï¼")
            except Exception as e:
                st.error(f"æ— æ³•ä¿å­˜æ•°æ®åº“ï¼Œè¯·å…³é—­å·²æ‰“å¼€çš„ Excel æ–‡ä»¶ï¼é”™è¯¯: {e}")
        progress_text.empty()
        pbar.empty()
    
    return db_df

# --- ç•Œé¢å±•ç¤º ---
st.title("âš–ï¸ æ•°å­—åŒ–è§„ç¨‹æŸ¥é˜…å¹³å°")

try:
    df = sync_data()
except Exception as e:
    st.exception(e) # è¿™ä¼šå°†è¯¦ç»†çš„é”™è¯¯æ ˆæ˜¾ç¤ºåœ¨ç½‘é¡µä¸Š
    st.stop()

if not df.empty:
    search_query = st.text_input("ğŸ” è¾“å…¥å…³é”®è¯æˆ–æ¡æ¬¾å·æœç´¢")
    
    if search_query:
        display_df = df[df['å†…å®¹'].str.contains(search_query, case=False, na=False) | (df['æ¡æ¬¾å·'] == search_query)]
        st.subheader(f"æ‰¾åˆ° {len(display_df)} æ¡ç»“æœ")
        st.dataframe(display_df, use_container_width=True)
    else:
        st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§é€‰æ‹©æ ‡å‡†ï¼Œæˆ–åœ¨ä¸Šæ–¹æœç´¢ã€‚ç›®å‰åº“å†…å·²æœ‰æ•°æ®ï¼š")
        st.write(df.groupby('æ ‡å‡†å·').size().reset_index(name='æ¡æ¬¾æ•°é‡'))
else:
    st.info("è¯·å°†æ–‡ä»¶æ”¾å…¥ data æ–‡ä»¶å¤¹ã€‚")
